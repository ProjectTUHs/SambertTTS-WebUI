import subprocess
import random
import os
from pathlib import Path
import librosa
from scipy.io import wavfile
import numpy as np
import torch
import csv
import whisper
import gradio as gr
import soundfile as sf

os.system("pip install --upgrade Cython==0.29.35")
os.system("pip install pysptk --no-build-isolation")
os.system("pip install kantts -f https://modelscope.oss-cn-beijing.aliyuncs.com/releases/repo.html")
os.system("pip install tts-autolabel -f https://modelscope.oss-cn-beijing.aliyuncs.com/releases/repo.html")

import sox

def split_long_audio(model, filepaths, save_dir="data_dir", out_sr=44100):
    if isinstance(filepaths, str):
        filepaths = [filepaths]

    for file_idx, filepath in enumerate(filepaths):

        save_path = Path(save_dir)
        save_path.mkdir(exist_ok=True, parents=True)

        print(f"Transcribing file {file_idx}: '{filepath}' to segments...")
        result = model.transcribe(filepath, word_timestamps=True, task="transcribe", beam_size=5, best_of=5)
        segments = result['segments']

        wav, sr = librosa.load(filepath, sr=None, offset=0, duration=None, mono=True)
        wav, _ = librosa.effects.trim(wav, top_db=20)
        peak = np.abs(wav).max()
        if peak > 1.0:
            wav = 0.98 * wav / peak
        wav2 = librosa.resample(wav, orig_sr=sr, target_sr=out_sr)
        wav2 /= max(wav2.max(), -wav2.min())

        for i, seg in enumerate(segments):
            start_time = seg['start']
            end_time = seg['end']
            wav_seg = wav2[int(start_time * out_sr):int(end_time * out_sr)]
            wav_seg_name = f"{file_idx}_{i}.wav"
            out_fpath = save_path / wav_seg_name
            wavfile.write(out_fpath, rate=out_sr, data=(wav_seg * np.iinfo(np.int16).max).astype(np.int16))

device = 'cuda' if torch.cuda.is_available() else 'cpu'
whisper_size = "medium"
whisper_model = whisper.load_model(whisper_size).to(device)

from modelscope.tools import run_auto_label

from modelscope.models.audio.tts import SambertHifigan
from modelscope.pipelines import pipeline
from modelscope.utils.constant import Tasks

from modelscope.metainfo import Trainers
from modelscope.trainers import build_trainer
from modelscope.utils.audio.audio_utils import TtsTrainType

pretrained_model_id = 'damo/speech_personal_sambert-hifigan_nsf_tts_zh-cn_pretrain_16k'

dataset_id = "/home/user/app/output_training_data/"
pretrain_work_dir = "/home/user/app/pretrain_work_dir/"


def auto_label(Voicetoclone, VoiceMicrophone):
    if VoiceMicrophone is not None:
        audio = VoiceMicrophone
    else:
        audio = Voicetoclone
        
    try:
        split_long_audio(whisper_model, audio, "/home/user/app/test_wavs/")
        input_wav = "/home/user/app/test_wavs/"
        output_data = "/home/user/app/output_training_data/"
        ret, report = run_auto_label(input_wav=input_wav, work_dir=output_data, resource_revision="v1.0.7")
    
    except Exception as e:
        print(e)
    return "æ ‡æ³¨æˆåŠŸ"



def train(train_step):
    try:

        train_info = {
            TtsTrainType.TRAIN_TYPE_SAMBERT: {  # é…ç½®è®­ç»ƒAMï¼ˆsambertï¼‰æ¨¡å‹
                'train_steps': int(train_step / 20) * 20 + 2,               # è®­ç»ƒå¤šå°‘ä¸ªstep
                'save_interval_steps': int(train_step / 20) * 20,           # æ¯è®­ç»ƒå¤šå°‘ä¸ªstepä¿å­˜ä¸€æ¬¡checkpoint
                'log_interval': int(train_step / 20) * 20                   # æ¯è®­ç»ƒå¤šå°‘ä¸ªstepæ‰“å°ä¸€æ¬¡è®­ç»ƒæ—¥å¿—
            }
        }

        kwargs = dict(
            model=pretrained_model_id,                  # æŒ‡å®šè¦finetuneçš„æ¨¡å‹
            model_revision = "v1.0.6",
            work_dir=pretrain_work_dir,                 # æŒ‡å®šä¸´æ—¶å·¥ä½œç›®å½•
            train_dataset=dataset_id,                   # æŒ‡å®šæ•°æ®é›†id
            train_type=train_info                       # æŒ‡å®šè¦è®­ç»ƒç±»å‹åŠå‚æ•°
        )

        trainer = build_trainer(Trainers.speech_kantts_trainer,
                            default_args=kwargs)

        trainer.train()

    except Exception as e:
        print(e)

    return "è®­ç»ƒå®Œæˆ"


# ä¿å­˜æ¨¡å‹

import shutil

import datetime

def save_model(worked_dir,dest_dir):
    worked_dir = "/home/user/app/pretrain_work_dir"
    dest_dir = "/home/user/app/trained_model"

    if os.listdir(worked_dir): 

        now = datetime.datetime.now()
        
        date_str = now.strftime("%Y%m%d%H%M%S")
        
        dest_folder = os.path.join(dest_dir, date_str)
        
        shutil.copytree(worked_dir, dest_folder)

                # List of files and directories to delete
        files_to_delete = [
            "tmp_voc",
            "tmp_am/ckpt/checkpoint_2400000.pth",
            "orig_model/description",
            "orig_model/.mdl",
            "orig_model/.msc",
            "orig_model/README.md",
            "orig_model/resource",
            "orig_model/description",
            "orig_model/basemodel_16k/sambert",
            "orig_model/basemodel_16k/speaker_embedding",
            "data/duration",
            "data/energy",
            "data/f0",
            "data/frame_energy",
            "data/frame_f0",
            "data/frame_uv",
            "data/mel",
            "data/raw_duration",
            "data/wav",
            "data/am_train.lst",
            "data/am_valid.lst",
            "data/badlist.txt",
            "data/raw_metafile.txt",
            "data/Script.xml",
            "data/train.lst",
            "data/valid.lst",
            "data/se/0_*"
        ]

        for item in files_to_delete:
            item_path = os.path.join(dest_folder, item)
            if os.path.exists(item_path):
                if os.path.isdir(item_path):
                    shutil.rmtree(item_path)
                else:
                    os.remove(item_path)
        
        shutil.rmtree("/home/yiho/Personal-TTS-v3/output_training_data")
        shutil.rmtree("/home/yiho/Personal-TTS-v3/pretrain_work_dir")
        shutil.rmtree("/home/yiho/Personal-TTS-v3/test_wavs")
        
        os.mkdir("/home/yiho/Personal-TTS-v3/output_training_data")
        os.mkdir("/home/yiho/Personal-TTS-v3/pretrain_work_dir")
        os.mkdir("/home/yiho/Personal-TTS-v3/test_wavs")
        
        return f"æ¨¡å‹å·²æˆåŠŸä¿å­˜ä¸º {date_str}"
    else: 
        return "ä¿å­˜å¤±è´¥ï¼Œæ¨¡å‹å·²ä¿å­˜æˆ–å·²è¢«æ¸…é™¤"


import random

def infer(text):

  model_dir = "/home/user/app/pretrain_work_dir/"

  test_infer_abs = {
      'voice_name':
      'F7',
      'am_ckpt':
      os.path.join(model_dir, 'tmp_am', 'ckpt'),
      'am_config':
      os.path.join(model_dir, 'tmp_am', 'config.yaml'),
      'voc_ckpt':
      os.path.join(model_dir, 'orig_model', 'basemodel_16k', 'hifigan', 'ckpt'),
      'voc_config':
      os.path.join(model_dir, 'orig_model', 'basemodel_16k', 'hifigan',
              'config.yaml'),
      'audio_config':
      os.path.join(model_dir, 'data', 'audio_config.yaml'),
      'se_file':
      os.path.join(model_dir, 'data', 'se', 'se.npy')
  }
  kwargs = {'custom_ckpt': test_infer_abs}

  model_id = SambertHifigan(os.path.join(model_dir, "orig_model"), **kwargs)

  inference = pipeline(task=Tasks.text_to_speech, model=model_id)
  output = inference(input=text) 


  now = datetime.datetime.now()
  date_str = now.strftime("%Y%m%d%H%M%S")
  rand_num = random.randint(1000, 9999)
  filename = date_str + str(rand_num)
  

  with open(filename + "0.wav", mode='bx') as f:
      f.write(output["output_wav"])


  y, sr = librosa.load(filename + "0.wav")

  S = librosa.stft(y)

  noise = S[np.abs(S) < np.percentile(S, 95)]
  noise_mean, noise_std = np.mean(noise), np.std(noise)

  filter_ = np.ones_like(S)
  filter_[np.abs(S) < noise_mean + 2 * noise_std] = 0

  filtered_S = filter_ * S

  filtered_y = librosa.istft(filtered_S)

  sf.write(filename + "testfile.wav", filtered_y, sr)


  os.remove(filename + "0.wav")


  return filename + "testfile.wav"


def infer_custom(model_name, text, noise_level): 

  custom_model_dir = os.path.join("/home/user/app/trained_model/", model_name) 

  custom_infer_abs = {
      'voice_name':
      'F7', 
      'am_ckpt':
      os.path.join(custom_model_dir, 'tmp_am', 'ckpt'),
      'am_config':
      os.path.join(custom_model_dir, 'tmp_am', 'config.yaml'),
      'voc_ckpt':
      os.path.join(custom_model_dir, 'orig_model', 'basemodel_16k', 'hifigan', 'ckpt'),
      'voc_config':
      os.path.join(custom_model_dir, 'orig_model', 'basemodel_16k', 'hifigan',
              'config.yaml'),
      'audio_config':
      os.path.join(custom_model_dir, 'data', 'audio_config.yaml'),
      'se_file':
      os.path.join(custom_model_dir, 'data', 'se', 'se.npy')
  }
  kwargs = {'custom_ckpt': custom_infer_abs}

  model_id = SambertHifigan(os.path.join(custom_model_dir, "orig_model"), **kwargs)

  inference = pipeline(task=Tasks.text_to_speech, model=model_id)
  output = inference(input=text)


  now = datetime.datetime.now()
  date_str = now.strftime("%Y%m%d%H%M%S")
  rand_num = random.randint(1000, 9999)
  filename = date_str + str(rand_num)


  with open(filename + ".wav", mode='bx') as f:
      f.write(output["output_wav"])




  y, sr = librosa.load(filename + ".wav")

  S = librosa.stft(y)

  noise = S[np.abs(S) < np.percentile(S, 95)]
  noise_mean, noise_std = np.mean(noise), np.std(noise)

  filter_ = np.ones_like(S)
  filter_[np.abs(S) < noise_mean + noise_level * noise_std] = 0

  filtered_S = filter_ * S

  filtered_y = librosa.istft(filtered_S)

  sf.write(filename + "customfile.wav", filtered_y, sr)

  os.remove(filename + ".wav")

  return filename + "customfile.wav"



trained_model = "/home/user/app/trained_model/"


def update_model_dropdown(inp3):

    model_list = os.listdir(trained_model)

    return gr.Dropdown(choices=model_list, value=inp3)


def rename_model(old_name, new_name):

    if not os.path.isdir(os.path.join(trained_model, old_name)):
        return "æ¨¡å‹åç§°ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°è¾“å…¥ï¼"
    else:
        try:
            os.rename(os.path.join(trained_model, old_name), os.path.join(trained_model, new_name))
            return "æ¨¡å‹é‡å‘½åæˆåŠŸï¼"
        except OSError:
            return "æ–°åç§°å·²ç»å­˜åœ¨ï¼Œè¯·é‡æ–°è¾“å…¥ï¼"


# æ¸…é™¤è®­ç»ƒç¼“å­˜
def clear_cache(a):
    shutil.rmtree("/home/user/app/output_training_data")
    shutil.rmtree("/home/user/app/pretrain_work_dir")
    shutil.rmtree("/home/user/app/test_wavs")

    os.mkdir("/home/user/app/output_training_data")
    os.mkdir("/home/user/app/pretrain_work_dir")
    os.mkdir("/home/user/app/test_wavs")
    return "å·²æ¸…é™¤ç¼“å­˜ï¼Œè¯·è¿”å›è®­ç»ƒé¡µé¢é‡æ–°è®­ç»ƒ"


from textwrap import dedent



def FRCRN_De_Noise(noise_wav, noisemic_wav):
  
  if noisemic_wav is not None:
      noise_audio = noisemic_wav
  else:
      noise_audio = noise_wav
    
  ans = pipeline(
    Tasks.acoustic_noise_suppression,
    model='/home/yiho/Personal-TTS-v3/damo/speech_frcrn_ans_cirm_16k')

  now = datetime.datetime.now()
  date_str = now.strftime("%Y%m%d%H%M%S")
  rand_num = random.randint(1000, 9999)
  filename = date_str + str(rand_num)

  result = ans(
    noise_audio,
    output_path= filename + "AIdenoise.wav" )
  
  return filename + "AIdenoise.wav"

def Normal_De_Noise(noise_wav, noisemic_wav, noise_level):
  if noisemic_wav is not None:
      noise_audio = noisemic_wav
  else:
      noise_audio = noise_wav
  
  now = datetime.datetime.now()
  date_str = now.strftime("%Y%m%d%H%M%S")
  rand_num = random.randint(1000, 9999)
  filename = date_str + str(rand_num)


  y, sr = librosa.load(noise_audio)

  S = librosa.stft(y)

  noise = S[np.abs(S) < np.percentile(S, 95)]
  noise_mean, noise_std = np.mean(noise), np.std(noise)

  filter_ = np.ones_like(S)
  filter_[np.abs(S) < noise_mean + noise_level * noise_std] = 0

  filtered_S = filter_ * S

  filtered_y = librosa.istft(filtered_S)

  sf.write(filename + "denoise.wav", filtered_y, sr)

  return filename + "denoise.wav"


app = gr.Blocks()

with app:
    gr.Markdown("# <center>ğŸ¥³ğŸ¶ğŸ¡ - Sambertä¸­æ–‡å£°éŸ³å…‹éš†</center>")
    gr.Markdown("## <center>ğŸŒŸ - è®­ç»ƒ3åˆ†é’Ÿï¼Œæ¨ç†10ç§’é’Ÿï¼Œä¸­è‹±çœŸå®æ‹Ÿå£° </center>")
    gr.Markdown("### <center>ğŸŒŠ - åŸºäºSambertHifiGané¡¹ç›®ä¿®æ”¹è€Œæ¥ï¼Œæ·»åŠ ä¸¤ç§é™å™ªåŠŸèƒ½ã€æ¨¡å‹ç®¡ç†åŠŸèƒ½ç­‰")

    with gr.Tabs(): 
        with gr.TabItem("ä¸€é”®è®­ç»ƒ"): 
            with gr.Row():
              with gr.Column():
                inp1 = gr.Audio(type="filepath", sources="upload", label="æ–¹æ¡ˆä¸€ï¼šè¯·ä»æœ¬åœ°ä¸Šä¼ ä¸€æ®µè¯­éŸ³")
                inp_micro = gr.Audio(type="filepath", sources="microphone", label="æ–¹æ¡ˆäºŒï¼šè¯·ç”¨éº¦å…‹é£å½•åˆ¶æ‚¨çš„å£°éŸ³")
              with gr.Column():
                out1 = gr.Textbox(label="æ ‡æ³¨æƒ…å†µ", lines=1, interactive=False)
                out2 = gr.Textbox(label="è®­ç»ƒæƒ…å†µ", lines=1, interactive=False)
                inp2 = gr.Slider(label="è®­ç»ƒæ­¥æ•°(éœ€è¦ä¸º20çš„å€æ•°)", minimum=200, maximum=4000, value=400, min_width=40)
                inp3 = gr.Textbox(label="è¯·åœ¨è¿™é‡Œå¡«å†™æ‚¨æƒ³åˆæˆçš„æ–‡æœ¬", placeholder="æƒ³è¯´å´è¿˜æ²¡è¯´çš„ è¿˜å¾ˆå¤š...", lines=3, interactive=True)
              with gr.Column():
                out3 = gr.Audio(type="filepath", label="ä¸ºæ‚¨åˆæˆçš„ä¸“å±éŸ³é¢‘")
                out4 = gr.Textbox(label="ä¿å­˜æƒ…å†µ", lines=1, interactive=False)
            with gr.Row():
              btn1 = gr.Button("1.æ ‡æ³¨æ•°æ®")
              btn2 = gr.Button("2.å¼€å§‹è®­ç»ƒ")
              btn3 = gr.Button("3.ä¸€é”®æ¨ç†", variant="primary")
              btn4 = gr.Button("4.ä¿å­˜æ¨¡å‹", variant="primary") 
          
            btn1.click(auto_label, [inp1, inp_micro], out1)
            btn2.click(train, inp2, out2)
            btn3.click(infer, inp3, out3)
            btn4.click(save_model, out1, out4) 
            with gr.Accordion("ğŸ“’ è®­ç»ƒæ•™ç¨‹", open=True):
              _ = f""" å¦‚ä½•å¼€å§‹è®­ç»ƒ: 
                  * ç¬¬ä¸€æ­¥ï¼Œé€‰æ‹© [æ–¹æ¡ˆä¸€] æˆ– [æ–¹æ¡ˆäºŒ] ä¸Šä¼ ä¸€åˆ†é’Ÿå·¦å³çš„éŸ³é¢‘ï¼Œæ³¨æ„è¦åå­—æ¸…æ™°ã€æ„Ÿæƒ…é¥±æ»¡ã€éŸ³è‰²çº¯å‡€ä¸å«æ‚éŸ³
                  * ç¬¬äºŒæ­¥ï¼Œç‚¹å‡»â€œæ ‡æ³¨æ•°æ®â€ï¼Œç­‰åˆ°æç¤ºæ ‡æ³¨æˆåŠŸåï¼Œé€‰æ‹©åˆé€‚çš„è®­ç»ƒæ­¥æ•°ï¼Œç‚¹å‡»â€œå¼€å§‹è®­ç»ƒâ€ç­‰å¾…è®­ç»ƒå®Œæˆ
                  * ç¬¬ä¸‰æ­¥ï¼Œè€å¿ƒç­‰å¾…è®­ç»ƒæˆåŠŸåï¼Œåœ¨æ–‡æœ¬æ¡†å†…è¾“å…¥æƒ³è¦ç”Ÿæˆçš„æ–‡å­—ï¼Œç‚¹å‡»â€œä¸€é”®ç”Ÿæˆâ€æŒ‰é’®ï¼Œç”Ÿæˆå…‹éš†åçš„è¯­éŸ³
                  * ï¼ï¼æ³¨æ„ï¼ï¼  ä¸è¦ç”Ÿæˆä¼šå¯¹ä¸ªäººä»¥åŠç»„ç»‡é€ æˆä¾µå®³çš„å†…å®¹
                  * å¦‚æœæ‚¨çš„è®­ç»ƒç´ ææ¯”è¾ƒå˜ˆæ‚ï¼Œæ‚¨å¯ä»¥åœ¨[AIé™å™ª]é€‰é¡¹å¡ä¸Šä¼ æˆ–å½•åˆ¶è®­ç»ƒéŸ³é¢‘ï¼Œé™å™ªåå†ä¸Šä¼ åˆ°è®­ç»ƒç•Œé¢
                  * å¦‚æœæ‚¨éœ€è¦ç”¨æ–¹æ¡ˆäºŒå½•åˆ¶æ‚¨çš„å£°éŸ³ï¼Œä»¥ä¸‹æ˜¯ä¸€æ®µé•¿åº¦åˆé€‚çš„æ–‡æœ¬ï¼Œä¾›æ‚¨æœ—è¯»å¹¶å½•åˆ¶ï¼š

                  è®°å¾—æ˜¥å¤©çš„æ—¶å€™ï¼Œå°è‰å°±è½¬å‡ºåœ°é¢ï¼Œæ ‘ä¸Šçš„å¶å­ä¹ŸæŠ½å‡ºæ¥äº†ï¼Œå¤§åœ°ä¸€ç‰‡ç»¿è‰²ï¼Œå°±åƒç©¿ä¸Šäº†ä¸€ä»¶ç»¿è¡£è£³ã€‚æˆ‘å°±ä¸å°å­©å­ä¸€èµ·åˆ°ç”°é‡å»æ‰èœ»èœ“ï¼Œç©æ¸¸æˆï¼Œæ¯”å¦‚è€é¹°åˆä½œå°é¸¡æˆ–æ˜¯æ‰è¿·è—ï¼Œåˆæˆ–æ˜¯è·³æ ¼å­ã€‚åˆ°äº†å¤å¤©ï¼Œå¤©æ°”çƒ­äº†ï¼Œæˆ‘å°±ä¼šä¸å°å­©å­åˆ°æ°´åº“é‡Œé¢æ¸¸æ³³ï¼Œé‚£æ—¶å€™æ°´åº“çš„å®‰å…¨ç³»æ•°è¿˜ä¸æ˜¯å¾ˆé«˜ï¼Œå‡ ä¹æ¯å¹´éƒ½ä¼šæœ‰äº‹æ•…å‘ç”Ÿï¼Œæ‰€ä»¥çˆ¶æ¯éƒ½ä¸ä¼šè®©æˆ‘å»æ¸¸æ³³çš„ï¼Œè¢«å‘ç°ä¹‹åå½“ç„¶å°±æ˜¯å¤„ç½šæˆ–æ˜¯è´£éª‚äº†ã€‚å¯æ˜¯é‚£æ—¶å€™è‡ªå·±çœŸçš„å¾ˆå›é€†ï¼Œä¹Ÿä¸çŸ¥é“ä»€ä¹ˆæ˜¯å±é™©ï¼Œè¢«å¤„ç½šä¹‹åä¸‹ä¸€æ¬¡è¿˜æ˜¯å›å»çš„ã€‚åˆ°äº†ç§‹å¤©ï¼Œç”°é‡ä¸€ç‰‡é‡‘é»„ï¼Œå±±ä¸Šçš„é‡æœä¹Ÿæˆç†Ÿäº†ï¼Œæˆ‘å°±ä¼šä¸è‡ªå·±çš„ä¼™ä¼´æ‹¿ç€ç¯®å­åˆ°ä¸Šå±±å»é‡‡ï¼Œé‡‡å›æ¥äº†è¿˜è¦è·Ÿè‡ªå·±çš„å¥½æœ‹å‹ä¸€èµ·åˆ†äº«ã€‚
                
                  """
              gr.Markdown(dedent(_))

        with gr.TabItem("å£°éŸ³åˆæˆ"): 
            with gr.Row():
              with gr.Column():
                inp21 = gr.Dropdown(label="è¯·é€‰æ‹©ä¸€ä¸ªæ¨¡å‹", choices=os.listdir(trained_model)) 
                inp22 = gr.Slider(label="é™å™ªå¼ºåº¦(ä¸º0æ—¶ä¸é™å™ª)", minimum=0, maximum=3, value=2)
              with gr.Column():
                inp23 = gr.Textbox(label="è¯·åœ¨è¿™é‡Œå¡«å†™æ‚¨æƒ³åˆæˆçš„æ–‡æœ¬", placeholder="æƒ³è¯´å´è¿˜æ²¡è¯´çš„ è¿˜å¾ˆå¤š...", lines=3,  interactive=True)
              with gr.Column():
                out21 = gr.Audio(type="filepath", label="ä¸ºæ‚¨åˆæˆçš„ä¸“å±éŸ³é¢‘", interactive=False)
            with gr.Row():
              btn21 = gr.Button("åˆ·æ–°æ¨¡å‹åˆ—è¡¨") 
              btn22 = gr.Button("ä¸€é”®æ¨ç†", variant="primary") 

            btn21.click(update_model_dropdown, inp21, inp21)
            btn22.click(infer_custom, [inp21, inp23, inp22], out21) 
            with gr.Accordion("ğŸ“’ æ¨ç†æ•™ç¨‹", open=True):
              _ = f""" å¦‚ä½•æ¨ç†å£°éŸ³: 
                  * ç¬¬ä¸€æ­¥ï¼Œé€‰æ‹©ä¸€ä¸ªä½ æƒ³è¦ä½¿ç”¨çš„æ¨¡å‹ï¼Œå¦‚æœè®­ç»ƒåä¿å­˜çš„æ¨¡å‹æ— æ³•æ‰¾åˆ°è¯·ç‚¹å‡»â€œåˆ·æ–°æ¨¡å‹åˆ—è¡¨â€
                  * ç¬¬äºŒæ­¥ï¼Œåœ¨æ–‡æœ¬æ¡†å¤„è¾“å…¥ä½ æƒ³è¦ç”Ÿæˆçš„æ–‡æœ¬ï¼Œé€‰æ‹©é™å™ªå¼ºåº¦ï¼Œå¦‚æœæ— éœ€é™å™ªè¯·å°†å¼ºåº¦è®¾ä¸º0
                  * ç¬¬ä¸‰æ­¥ï¼Œç‚¹å‡»â€œä¸€é”®ç”Ÿæˆâ€æŒ‰é’®ï¼Œç”Ÿæˆå…‹éš†åçš„è¯­éŸ³
                  * ï¼ï¼æ³¨æ„ï¼ï¼  ä¸è¦ç”Ÿæˆä¼šå¯¹ä¸ªäººä»¥åŠç»„ç»‡é€ æˆä¾µå®³çš„å†…å®¹
                  * æ­¤å¤„ä½¿ç”¨çš„é™å™ªç®—æ³•ä¸ºæœºæ¢°é™å™ªï¼ŒéAIé™å™ªï¼Œå¦‚éœ€AIé™å™ªå¯ä»¥å°†ç”Ÿæˆçš„éŸ³é¢‘ä¸‹è½½åè½¬åˆ°â€œAIé™å™ªâ€é€‰é¡¹å¡è¿›è¡ŒAIé™å™ª

                  """
              gr.Markdown(dedent(_))
        
        with gr.TabItem("æ¨¡å‹ä¿®æ”¹"): 
            with gr.Row():
              with gr.Column():
                inp31 = gr.Dropdown(label="é€‰æ‹©é‡å‘½åçš„æ¨¡å‹", choices=os.listdir(trained_model)) 
              with gr.Column():
                inp32 = gr.Textbox(label="è¾“å…¥æ¨¡å‹å‘½å", placeholder="æ–°åç§°", lines=1,  interactive=True)
              with gr.Column():    
                out31 = gr.Textbox(label="ä¿å­˜æƒ…å†µ", lines=1, interactive=False)
            with gr.Row():
              btn31 = gr.Button("åˆ·æ–°æ¨¡å‹åˆ—è¡¨") 
              btn32 = gr.Button("é‡å‘½å", variant="primary") 

            btn31.click(update_model_dropdown, inp31, inp31)
            btn32.click(rename_model, [inp31, inp32], out31)
            with gr.Accordion("ğŸ“’ æ¨ç†æ•™ç¨‹", open=True):
              _ = f""" å¦‚ä½•ä¿®æ”¹æ¨¡å‹åç§°: 
                  * ç¬¬ä¸€æ­¥ï¼Œé€‰æ‹©ä¸€ä¸ªä½ æƒ³è¦ä¿®æ”¹çš„æ¨¡å‹ï¼Œå¦‚æœè®­ç»ƒåä¿å­˜çš„æ¨¡å‹æ— æ³•æ‰¾åˆ°è¯·ç‚¹å‡»â€œåˆ·æ–°æ¨¡å‹åˆ—è¡¨â€
                  * ç¬¬äºŒæ­¥ï¼Œåœ¨æ–‡æœ¬æ¡†å¤„è¾“å…¥ä½ æƒ³è¦ä¿®æ”¹çš„æ¨¡å‹åç§°ï¼Œæ¨èä»¥â€œ[è®­ç»ƒæ­¥æ•°]æ—¶é—´-åç§°â€æ¥å‘½å
                  * ç¬¬ä¸‰æ­¥ï¼Œç‚¹å‡»â€œé‡å‘½åâ€æŒ‰é’®å¯¹æ¨¡å‹é‡å‘½å

                  """
              gr.Markdown(dedent(_))              

        with gr.TabItem("AIé™å™ª"): 
            with gr.Row():
              with gr.Column():
                inp41 = gr.Audio(type="filepath", sources="upload", label="æ–¹æ¡ˆä¸€ï¼šè¯·ä»æœ¬åœ°ä¸Šä¼ ä¸€æ®µè¯­éŸ³")
                inp_micro42 = gr.Audio(type="filepath", sources="microphone", label="æ–¹æ¡ˆäºŒï¼šè¯·ç”¨éº¦å…‹é£å½•åˆ¶æ‚¨çš„å£°éŸ³")
              with gr.Column():
                out41 = gr.Audio(type="filepath", label="é™å™ªåçš„éŸ³é¢‘", interactive=False)
                inp43 = gr.Slider(label="æœºæ¢°é™å™ªå¼ºåº¦(éAIé™å™ª)", minimum=0, maximum=3, value=2)  
                btn41 = gr.Button("æœºæ¢°é™å™ª")
                btn42 = gr.Button("ä¸€é”®AIé™å™ª", variant="primary")
            
            btn41.click(Normal_De_Noise, [inp41, inp_micro42, inp43], out41)
            btn42.click(FRCRN_De_Noise, [inp41, inp_micro42], out41)
            with gr.Accordion("ğŸ“’ AIé™å™ª", open=True):
              _ = f""" å¦‚ä½•ä½¿ç”¨AIé™å™ª: 
                  * ç¬¬ä¸€æ­¥ï¼Œåœ¨[æ–¹æ¡ˆä¸€]ä¸Šä¼ ä½ æƒ³è¦é™å™ªçš„éŸ³é¢‘ï¼Œæˆ–è€…åœ¨[æ–¹æ¡ˆäºŒ]å½•åˆ¶éŸ³é¢‘
                  * ç¬¬äºŒæ­¥ï¼Œç‚¹å‡»â€œä¸€é”®AIé™å™ªâ€è¿›è¡Œé™å™ª
                  * ç¬¬ä¸‰æ­¥ï¼Œä¸‹è½½é™å™ªåçš„éŸ³é¢‘
                  * å¦‚æœæ‚¨çš„è®­ç»ƒç´ ææ¯”è¾ƒå˜ˆæ‚ï¼Œæ‚¨å¯ä»¥åœ¨æ­¤å¤„ä¸Šä¼ æˆ–å½•åˆ¶è®­ç»ƒéŸ³é¢‘ï¼Œé™å™ªåå†ä¸Šä¼ åˆ°è®­ç»ƒç•Œé¢
                  * å¦‚æœæ‚¨éœ€è¦ç”¨æ–¹æ¡ˆäºŒå½•åˆ¶æ‚¨çš„å£°éŸ³ï¼Œä»¥ä¸‹æ˜¯ä¸€æ®µé•¿åº¦åˆé€‚çš„æ–‡æœ¬ï¼Œä¾›æ‚¨æœ—è¯»å¹¶å½•åˆ¶ï¼š

                  è®°å¾—æ˜¥å¤©çš„æ—¶å€™ï¼Œå°è‰å°±è½¬å‡ºåœ°é¢ï¼Œæ ‘ä¸Šçš„å¶å­ä¹ŸæŠ½å‡ºæ¥äº†ï¼Œå¤§åœ°ä¸€ç‰‡ç»¿è‰²ï¼Œå°±åƒç©¿ä¸Šäº†ä¸€ä»¶ç»¿è¡£è£³ã€‚æˆ‘å°±ä¸å°å­©å­ä¸€èµ·åˆ°ç”°é‡å»æ‰èœ»èœ“ï¼Œç©æ¸¸æˆï¼Œæ¯”å¦‚è€é¹°åˆä½œå°é¸¡æˆ–æ˜¯æ‰è¿·è—ï¼Œåˆæˆ–æ˜¯è·³æ ¼å­ã€‚åˆ°äº†å¤å¤©ï¼Œå¤©æ°”çƒ­äº†ï¼Œæˆ‘å°±ä¼šä¸å°å­©å­åˆ°æ°´åº“é‡Œé¢æ¸¸æ³³ï¼Œé‚£æ—¶å€™æ°´åº“çš„å®‰å…¨ç³»æ•°è¿˜ä¸æ˜¯å¾ˆé«˜ï¼Œå‡ ä¹æ¯å¹´éƒ½ä¼šæœ‰äº‹æ•…å‘ç”Ÿï¼Œæ‰€ä»¥çˆ¶æ¯éƒ½ä¸ä¼šè®©æˆ‘å»æ¸¸æ³³çš„ï¼Œè¢«å‘ç°ä¹‹åå½“ç„¶å°±æ˜¯å¤„ç½šæˆ–æ˜¯è´£éª‚äº†ã€‚å¯æ˜¯é‚£æ—¶å€™è‡ªå·±çœŸçš„å¾ˆå›é€†ï¼Œä¹Ÿä¸çŸ¥é“ä»€ä¹ˆæ˜¯å±é™©ï¼Œè¢«å¤„ç½šä¹‹åä¸‹ä¸€æ¬¡è¿˜æ˜¯å›å»çš„ã€‚åˆ°äº†ç§‹å¤©ï¼Œç”°é‡ä¸€ç‰‡é‡‘é»„ï¼Œå±±ä¸Šçš„é‡æœä¹Ÿæˆç†Ÿäº†ï¼Œæˆ‘å°±ä¼šä¸è‡ªå·±çš„ä¼™ä¼´æ‹¿ç€ç¯®å­åˆ°ä¸Šå±±å»é‡‡ï¼Œé‡‡å›æ¥äº†è¿˜è¦è·Ÿè‡ªå·±çš„å¥½æœ‹å‹ä¸€èµ·åˆ†äº«ã€‚
                  
                  * AIé™å™ªä¸æœºæ¢°é™å™ªçš„ä¸åŒï¼šæœºæ¢°é™å™ªä¸»è¦æ˜¯ç§»é™¤å£°éŸ³çš„æ¿€æ³¢ï¼Œä¼šå¯¹äººå£°é€ æˆä¸€å®šçš„ç ´åï¼Œè€ŒAIé™å™ªä¸»è¦æ˜¯ç§»é™¤å£°éŸ³ä¸­çš„éäººå£°éƒ¨åˆ†ï¼Œå¯ä»¥å¤„ç†å¤æ‚çš„èƒŒæ™¯éŸ³é¢‘ç¯å¢ƒï¼Œä½†æ˜¯å¯¹äººå£°æœ¬èº«è´¨é‡é—®é¢˜å¤„ç†çš„æ•ˆæœä¸€èˆ¬                  
                  """
              gr.Markdown(dedent(_))            
        
        with gr.TabItem("ç¼“å­˜æ¸…ç†"): 
            with gr.Row():
              with gr.Column():
                gr.Markdown("### <center>æ³¨æ„ï¼Œè¿™ä¼šæ¸…é™¤[ä¸€é”®è®­ç»ƒ]ç•Œé¢ç”Ÿæˆçš„æ‰€æœ‰æ•°æ®")
                gr.Markdown("### <center>åŒ…æ‹¬æ ‡æ³¨æ•°æ®ï¼Œè®­ç»ƒæ•°æ®ï¼ŒåŠæœ€ç»ˆæ¨¡å‹")
                gr.Markdown("### <center>å¦‚éœ€ä¿å­˜æ¨¡å‹è¯·ç‚¹å‡»ä¿å­˜å½“å‰æ¨¡å‹æŒ‰é’®")
              with gr.Column():
                out97 = gr.Textbox(label="", lines=1, interactive=False)
                btn91 = gr.Button("ä¿å­˜å½“å‰æ¨¡å‹", ) 
                btn92 = gr.Button("æ¸…ç©ºç¼“å­˜æ•°æ®", variant="primary") 
            
            btn91.click(save_model, out1, out97) 
            btn92.click(clear_cache, out1, out97)




            

    with gr.Accordion("ğŸ“’ ä½¿ç”¨æŒ‡å—", open=False):
        _ = f""" å¦‚ä½•ä½¿ç”¨æ­¤ç¨‹åº: 
            * [ä¸€é”®è®­ç»ƒ] ï¼š ä¸Šä¼ æˆ–å½•åˆ¶éŸ³é¢‘ï¼Œç¨‹åºä¼šè‡ªåŠ¨æ ‡æ³¨éŸ³é¢‘ï¼Œä¸€é”®è®­ç»ƒæ¨¡å‹ï¼Œæ”¯æŒè®­ç»ƒåæ¨ç†è¯•å¬ï¼Œæ”¯æŒæ¨¡å‹ä¿å­˜
            * [å£°éŸ³åˆæˆ] ï¼š åœ¨è¿™é‡Œå¯ä»¥é€‰æ‹©å·²ä¿å­˜çš„æ¨¡å‹è¿›è¡Œæ¨ç†ï¼Œè‡ªå¸¦å¯è°ƒæœºæ¢°é™å™ªï¼Œå¯ä»¥ä»»æ„é€‰æ‹©å·²è®­ç»ƒçš„éŸ³é¢‘è¿›è¡Œæ¨ç†
            * [æ¨¡å‹ä¿®æ”¹] ï¼š åœ¨è¿™é‡Œå¯ä»¥é€‰æ‹©å·²ä¿å­˜çš„æ¨¡å‹è¿›è¡Œé‡å‘½åï¼Œæ–¹ä¾¿æ—¥åæ¨ç†ä½¿ç”¨
            * [ AIé™å™ª ] :  åœ¨è¿™é‡Œå¯ä»¥ä¸Šä¼ éŸ³é¢‘è¿›è¡ŒAIé™å™ªï¼Œä¸€é”®å»é™¤å™ªéŸ³æ‚å£°
            * [ç¼“å­˜æ¸…ç†] ï¼š å¦‚æœè®­ç»ƒæ—¶å‡ºç°æŠ¥é”™å¯ä»¥å°è¯•ç¼“å­˜æ¸…ç†ï¼Œæ¯æ¬¡ä¿å­˜æ¨¡å‹ä¼šè‡ªåŠ¨æ¸…ç†ç¼“å­˜ï¼Œå¦‚æœæœªä¿å­˜å°±é‡æ–°å¼€å§‹è®­ç»ƒéœ€è¦æ¸…ç†ç¼“å­˜
            * ï¼ï¼æ³¨æ„ï¼ï¼  ä¸è¦ç”Ÿæˆä¼šå¯¹ä¸ªäººä»¥åŠç»„ç»‡é€ æˆä¾µå®³çš„å†…å®¹
            * å¦‚æœæ‚¨éœ€è¦å½•åˆ¶æ‚¨çš„å£°éŸ³ï¼Œä»¥ä¸‹æ˜¯ä¸€æ®µé•¿åº¦åˆé€‚çš„æ–‡æœ¬ï¼Œä¾›æ‚¨æœ—è¯»å¹¶å½•åˆ¶ï¼š

            è®°å¾—æ˜¥å¤©çš„æ—¶å€™ï¼Œå°è‰å°±è½¬å‡ºåœ°é¢ï¼Œæ ‘ä¸Šçš„å¶å­ä¹ŸæŠ½å‡ºæ¥äº†ï¼Œå¤§åœ°ä¸€ç‰‡ç»¿è‰²ï¼Œå°±åƒç©¿ä¸Šäº†ä¸€ä»¶ç»¿è¡£è£³ã€‚æˆ‘å°±ä¸å°å­©å­ä¸€èµ·åˆ°ç”°é‡å»æ‰èœ»èœ“ï¼Œç©æ¸¸æˆï¼Œæ¯”å¦‚è€é¹°åˆä½œå°é¸¡æˆ–æ˜¯æ‰è¿·è—ï¼Œåˆæˆ–æ˜¯è·³æ ¼å­ã€‚åˆ°äº†å¤å¤©ï¼Œå¤©æ°”çƒ­äº†ï¼Œæˆ‘å°±ä¼šä¸å°å­©å­åˆ°æ°´åº“é‡Œé¢æ¸¸æ³³ï¼Œé‚£æ—¶å€™æ°´åº“çš„å®‰å…¨ç³»æ•°è¿˜ä¸æ˜¯å¾ˆé«˜ï¼Œå‡ ä¹æ¯å¹´éƒ½ä¼šæœ‰äº‹æ•…å‘ç”Ÿï¼Œæ‰€ä»¥çˆ¶æ¯éƒ½ä¸ä¼šè®©æˆ‘å»æ¸¸æ³³çš„ï¼Œè¢«å‘ç°ä¹‹åå½“ç„¶å°±æ˜¯å¤„ç½šæˆ–æ˜¯è´£éª‚äº†ã€‚å¯æ˜¯é‚£æ—¶å€™è‡ªå·±çœŸçš„å¾ˆå›é€†ï¼Œä¹Ÿä¸çŸ¥é“ä»€ä¹ˆæ˜¯å±é™©ï¼Œè¢«å¤„ç½šä¹‹åä¸‹ä¸€æ¬¡è¿˜æ˜¯å›å»çš„ã€‚åˆ°äº†ç§‹å¤©ï¼Œç”°é‡ä¸€ç‰‡é‡‘é»„ï¼Œå±±ä¸Šçš„é‡æœä¹Ÿæˆç†Ÿäº†ï¼Œæˆ‘å°±ä¼šä¸è‡ªå·±çš„ä¼™ä¼´æ‹¿ç€ç¯®å­åˆ°ä¸Šå±±å»é‡‡ï¼Œé‡‡å›æ¥äº†è¿˜è¦è·Ÿè‡ªå·±çš„å¥½æœ‹å‹ä¸€èµ·åˆ†äº«ã€‚
                
            """
        gr.Markdown(dedent(_))


    gr.Markdown("### <center>æ³¨æ„â—ï¼šè¯·ä¸è¦ç”Ÿæˆä¼šå¯¹ä¸ªäººä»¥åŠç»„ç»‡é€ æˆä¾µå®³çš„å†…å®¹ï¼Œæ­¤ç¨‹åºä»…ä¾›ç§‘ç ”ã€å­¦ä¹ åŠä¸ªäººå¨±ä¹ä½¿ç”¨ã€‚</center>")
    gr.HTML('''
        <div class="footer">
                    <p>ğŸŒŠğŸï¸ğŸ¶ - æ±Ÿæ°´ä¸œæµæ€¥ï¼Œæ»”æ»”æ— å°½å£°ã€‚ æ˜Â·é¡¾ç’˜
                    </p>
        </div>
    ''')


app.launch(show_error=True, share=False)
